

[MVUI]

# Title of the Mobile VUI window
window_title: Gerry, the Green Grocer

# VUI UI
background_colour: #000000

# VUI UI text decoration
typeface: Helvetica
font_size: 32
text_colour: #ffffff

# Initial text on the Mobile VUI window
initial_text: Welcome to Gerry, the Virtual Green Grocer<br><br>Please wait a moment...

; Size of the orb itself
orb_size: 120

; Maximum size of the animations around the orb, including the orb
orb_size_max: 240

; Enable fluttering when listening (uses a mic input)
orb_enable_flutter: True

; Size of the orb's border
orb_width: 10

; Colour of the orb when the VUI is resting
orb_resting: #223247

; Colour of the orb when the VUI is listening
orb_listening: #513469

; Colour of the orb when the VUI is computing
orb_busy: #e1e1e1

; Colour of the orb when the VUI is speaking
orb_speaking: #AB3F7D

; Colour of the orb flutter
orb_flutter_colour: #49515C



[Input]

# Arbitrary factor that reduces sensitivity of the volume detected
# (lower is more sensitive)
sensitivity: 1000



[Recognition]

# (Deprecated) Google Speech Recognition API key
#   -> this should be a mixed-case string
google_speech_recognition_api_key: 
google_speech_recognition_language: en-GB

# Google Cloud to Speech Recognition API key
#   -> copy contents of JSON string (can do multiple lines if indented!)
google_cloud_stt_credentials: 
google_cloud_stt_language: en-GB

# Wit.ai API key
#  -> 32-character uppercase alphanumeric strings
witai_api_key:

# Microsoft Bing API key
#  -> 32-character lowercase hexadecimal strings
bing_api_key:
bing_language: en-GB

# Microsoft Azure Speech API key
#  -> 32-character lowercase hexadecimal strings
azure_api_key:
azure_language: en-GB

# Amazon Lex AI
#  -> you also need the python boto3 module for this
lex_bot_name:
lex_bot_alias:
lex_user_id:
lex_access_key_id:
lex_secret_access_key:
lex_region:

# Houndify credentials
#  -> client IDs are Base64-encoded strings
#  -> client keys are Base64-encoded strings
houndify_client_id:
houndify_client_key:

# IBM Speech to Text
#  -> usernames are strings of the form XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
#  -> passwords are mixed-case alphanumeric strings
ibm_username:
ibm_password:
ibm_language: en-GB

# Tensorflow
tensor_graph:
tensor_label:


[ActiveMQ]

# ActiveMQ/STOMP server
host: localhost

# ActiveMQ/STOMP port
port: 61613

# ActiveMQ/STOMP username
username: admin

# ActiveMQ/STOMP password
password: password

# ActiveMQ/STOMP queue where NottReal will listen for status updates
nottreal_queue: /queue/nottreal

# ActiveMQ/STOMP queue where the Wizard's messages will be sent
destination_queue: /queue/voicesynth

# ActiveMQ/STOMP message format
message_text: message: %%s

# Message sent to interrupt any output
message_interrupt: interrupt

# Default format for messages about on the state NottReal should be in
message_state: state: %%s

# String for the nothing state messages sent to NottReal (substituted into message_text)
message_state_nothing: nothing

# String for the speaking state messages sent to NottReal (substituted into message_text)
message_state_speaking: speaking

# String for the listening state messages sent to NottReal (substituted into message_text)
message_state_listening: listening

# String for the computing state messages sent to NottReal (substituted into message_text)
message_state_computing: computing



[VoiceCerevoice]

#  Command to speak something (e.g. ./run_aria_tts.sh on macoS/Linux, run_arias_tts.bat on Windows)
command_speak: ./run_aria_tts.sh "%%s"

# Interrupt command (e.g. pkill -f run_arias_tts.sh on macOS/Linux, taskkill /F /IM run_arias_tts.bat on Windows)
command_interrupt: pkill -f run_arias_tts.sh



[VoiceMacOS]

# Options for the macOS voice
command_options: -vserena



[VoiceShellCmd]

# Command to speak something
command_speak: say "%%s"

# Command to cancel current voice output
command_interrupt: killall say
